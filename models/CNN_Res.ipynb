{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from torch.utils.data import sampler\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPSDatasetHelper():\n",
    "    #initialization \n",
    "    def __init__(self):\n",
    "        self.sample_rate=8000\n",
    "        self.dir= \"./daps_dict_unet2.json\"\n",
    "        openfile=open(self.dir, \"r\")\n",
    "        self.dataset_dict= json.load(openfile)\n",
    "        indx=2\n",
    "        self.keys={}\n",
    "        for key  in self.dataset_dict.keys():\n",
    "            if(key==\"produced\"):\n",
    "                self.keys[1]=key\n",
    "            else:\n",
    "                self.keys[indx]=key\n",
    "                indx+=1\n",
    "\n",
    "        self.num_files_per_category=len(self.dataset_dict[\"produced\"].keys())\n",
    "\n",
    "    #get the indexed file and sample rate\n",
    "    def get_indxd_file(self,indx,isLabel=False):\n",
    "        if(isLabel):\n",
    "            category=self.keys[1]\n",
    "        else:\n",
    "            #category=self.keys[np.random.randint(2,len(self.keys))]\n",
    "            #consider one category for now\n",
    "            category=self.keys[8]\n",
    "        data=cv2.imread(self.dataset_dict[category][str(indx)],0)\n",
    "        data= cv2.normalize(data, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        Id= self.dataset_dict[category][str(indx)].split(\"/\")[-1].split('.')[0]\n",
    "        return (data,Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPS(Dataset):\n",
    "    def __init__(self):\n",
    "        #super().__init__(self)\n",
    "        self.daps= DAPSDatasetHelper()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data,id=self.daps.get_indxd_file(index)\n",
    "        label,id=self.daps.get_indxd_file(index,True)\n",
    "        return (data,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.daps.keys)-1)*self.daps.num_files_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN=8000\n",
    "NUM_VAL=1000\n",
    "NUM_TEST=1000\n",
    "print_every = 100\n",
    "dataset_train = DAPS()\n",
    "loader_train = DataLoader(dataset_train, batch_size=16, num_workers=0,\n",
    "                          sampler=sampler.SequentialSampler(range(NUM_TRAIN)))\n",
    "loader_val= DataLoader(dataset_train, batch_size=16, num_workers=0,\n",
    "                          sampler=sampler.SequentialSampler(range(NUM_TRAIN,NUM_VAL+NUM_TRAIN)))\n",
    "loader_test = DataLoader(dataset_train, batch_size=16, num_workers=0,\n",
    "                          sampler=sampler.SequentialSampler(range(NUM_VAL+NUM_TRAIN, NUM_VAL+NUM_TRAIN+NUM_TEST)))\n",
    "\n",
    "helper= DAPSDatasetHelper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                kernel_size=(3,3),stride=1,padding=1)\n",
    "        #self.bnorm1=nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3,3),stride=1,padding=1)\n",
    "        #self.bnorm2=nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, c_list):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,1),stride=(2,1))\n",
    "        self.blocks = nn.ModuleList([block(c_list[i], c_list[i+1]) for i in range(len(c_list)-1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            #print(\"conv output\",x.shape)\n",
    "            filters.append(x)\n",
    "            x = self.pool(x)\n",
    "            #print(\"pool output\",x.shape)\n",
    "        return filters\n",
    "\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, c_list):\n",
    "        super().__init__()\n",
    "        self.up_cov = nn.ModuleList([nn.ConvTranspose2d(c_list[i], c_list[i+1], kernel_size=(2,1), stride=(2,1))\n",
    "                                                                    for i in range(len(c_list)-1)])\n",
    "        self.conv_blocks = nn.ModuleList([block(c_list[i], c_list[i+1]) for i in range(len(c_list)-1)])\n",
    "        \n",
    "\n",
    "    def forward(self, x, features):    \n",
    "        for i in range(len(self.conv_blocks)):\n",
    "            x = self.up_cov[i](x)\n",
    "           # print(\"up conv output\",features[i].shape, x.shape)\n",
    "            x = torch.cat([x, features[i]], dim=1)\n",
    "            x = self.conv_blocks[i](x)\n",
    "            #print(\"concat output\",x.shape)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        c_list=[1, 16, 32, 64, 128]\n",
    "        self.enc_blocks = encoder(c_list)\n",
    "        self.dec_blocks = decoder(c_list[::-1][:-1])\n",
    "        self.last_layer = nn.Conv2d(c_list[1], 1, kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        filters = self.enc_blocks(x)\n",
    "        x = self.dec_blocks(filters[-1], filters[::-1][1:])\n",
    "        return self.last_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNR loss where yhat is average power spectrum of de-nonlinearised/denoised signal/ clean signal power \n",
    "def Loss_SNR(yhat,y):\n",
    "    yhat=yhat.cpu().detach().numpy()\n",
    "    y=y.cpu().detach().numpy()\n",
    "    loss= np.mean(10*np.log(np.abs(yhat-y)/y))\n",
    "    loss=torch.from_numpy(loss)\n",
    "    loss=loss.to(device=device,dtype=dtype)\n",
    "    return loss\n",
    "\n",
    "#SNR loss where yhat is average power spectrum of de-nonlinearised/denoised signal/ clean signal power \n",
    "def Loss_MSE(yhat,y,lossfn):\n",
    "    loss=lossfn(yhat,y)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    print('Checking accuracy on validation set')\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    lossfn=nn.MSELoss()\n",
    "    mse=0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            x=x.unsqueeze(1)\n",
    "            y=y.unsqueeze(1) \n",
    "            yhat = model(x)\n",
    "            mse+= lossfn(y,yhat)\n",
    "        mse = mse / len(loader)\n",
    "        print(\"Validation loss is\", mse.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every=1\n",
    "def train_model(model, optimizer ,epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on DAPS.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: A Python function that performs the forward pass of the model.\n",
    "      It should have the signature scores = model_fn(x, params) where x is a\n",
    "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
    "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
    "      scores for the elements in x.\n",
    "    - params: List of PyTorch Tensors giving weights for the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
    "    \n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    lossfn=nn.MSELoss()\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            \n",
    "            #print(y.shape)          \n",
    "            #iterate over each stft frame \n",
    "            x=x.to(device=device, dtype=dtype)\n",
    "            y=y.to(device=device, dtype=dtype)\n",
    "\n",
    "            x=x.unsqueeze(1)\n",
    "            y=y.unsqueeze(1) \n",
    "\n",
    "            # Forward pass: compute scores and loss\n",
    "            yhat = model(x)\n",
    "            \n",
    "            loss = Loss_MSE(yhat, y, lossfn)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            # Update parameters. We don't want to backpropagate through the\n",
    "\n",
    "            \n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "            #check_accuracy_part2(loader_val, model_fn, params)\n",
    "            \n",
    "        check_accuracy(loader_val,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "model = UNet()\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                     momentum=0.9, nesterov=True)\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 499, loss = 0.0310\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/prasad/AEC/model/CNN_Res.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m train_model(model, optimizer,\u001b[39m30\u001b[39;49m)\n",
      "\u001b[1;32m/home/prasad/AEC/model/CNN_Res.ipynb Cell 10'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000008vscode-remote?line=50'>51</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, Iteration \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, loss = \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (e, t, loss\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000008vscode-remote?line=51'>52</a>\u001b[0m     \u001b[39m#check_accuracy_part2(loader_val, model_fn, params)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000008vscode-remote?line=53'>54</a>\u001b[0m check_accuracy(loader_val,model)\n",
      "\u001b[1;32m/home/prasad/AEC/model/CNN_Res.ipynb Cell 9'\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(loader, model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000012vscode-remote?line=12'>13</a>\u001b[0m     mse\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m lossfn(y,yhat)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000012vscode-remote?line=13'>14</a>\u001b[0m mse \u001b[39m=\u001b[39m mse \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/CNN_Res.ipynb#ch0000012vscode-remote?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValidation loss is\u001b[39m\u001b[39m\"\u001b[39m, mse\u001b[39m.\u001b[39;49mnumpy())\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer,30)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5c7ac77e593d0994949fe61f06040dedc773eb228097f0a804bc0d2d8d2f83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
