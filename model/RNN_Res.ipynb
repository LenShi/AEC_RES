{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from torch.utils.data import sampler\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPSDatasetHelper():\n",
    "    #Get the dataset dictionary \n",
    "    def get_file_descriptors(self,dirpath):\n",
    "        directory={}\n",
    "        dataset_path=self.dir\n",
    "        cwd= os.getcwd()\n",
    "        for i , (dirpath, dirname, filename) in enumerate(os.walk(dataset_path)):\n",
    "            if(dirpath!=dataset_path):\n",
    "                dirname=dirpath.split(\"/\")[-1]\n",
    "                files={}\n",
    "                file_list=[]\n",
    "                index=0\n",
    "                for file in filename:\n",
    "                    filepath = os.path.join( dirpath, file)\n",
    "                    if ( (filepath.endswith('.wav'))):\n",
    "                        if(file.startswith('.')):\n",
    "                            pass\n",
    "                        else:\n",
    "                            file_list.append(filepath)\n",
    "                file_list.sort()\n",
    "                if(len(file_list)>0):\n",
    "                    for filepath in file_list:\n",
    "                        files[index]=filepath\n",
    "                        index+=1\n",
    "                    directory[dirname]=files\n",
    "        return directory\n",
    "\n",
    "    #initialization \n",
    "    def __init__(self):\n",
    "        self.sample_rate=8000\n",
    "        self.dir= \"../dataset_daps/daps\"\n",
    "        self.dataset_dict=self.get_file_descriptors(self.dir)\n",
    "\n",
    "        #stft config\n",
    "        #frame size in ms\n",
    "        self.framesize=25\n",
    "        self.fft_len=self.sample_rate*self.framesize//1000\n",
    "        self.window_size=self.fft_len\n",
    "        self.hop_len=self.fft_len//2\n",
    "\n",
    "        indx=2\n",
    "        self.keys={}\n",
    "        for key  in self.dataset_dict.keys():\n",
    "            if(key==\"produced\"):\n",
    "                self.keys[1]=key\n",
    "            else:\n",
    "                self.keys[indx]=key\n",
    "                indx+=1\n",
    "\n",
    "        self.num_files_per_category=len(self.dataset_dict[\"produced\"].keys())\n",
    "\n",
    "    #get the indexed file and sample rate\n",
    "    def get_indxd_file(self,indx,isLabel=False):\n",
    "        if(isLabel):\n",
    "            category=self.keys[1]\n",
    "        else:\n",
    "            category=self.keys[np.random.randint(2,len(self.keys))]\n",
    "        data,sr= librosa.load(self.dataset_dict[category][indx])\n",
    "        Id= self.dataset_dict[category][indx].split(\"/\")[-1].split('.')[0]\n",
    "        return (data,sr, Id)\n",
    "\n",
    "    def resample_audio(self,file,sr):\n",
    "        out = librosa.resample(file, orig_sr=sr, target_sr=self.sample_rate)\n",
    "        return out\n",
    "\n",
    "    #get the train data and label at given index \n",
    "    def get_data(self,indx):\n",
    "        data,sr,Id_data = self.get_indxd_file(indx)\n",
    "        label,sr,Id_label = self.get_indxd_file(indx,True)\n",
    "        if(sr == self.sample_rate ):\n",
    "            pass\n",
    "        else:\n",
    "            data= self.resample_audio(data,sr)\n",
    "            label= self.resample_audio(label,sr)\n",
    "\n",
    "        return (data,label,Id_data,Id_label)\n",
    "\n",
    "\n",
    "    #get stft frames with 50% overlap\n",
    "    def getFeatures(self,file):\n",
    "\n",
    "        n_fft = self.fft_len\n",
    "        win_length = self.window_size\n",
    "        hop_length = self.hop_len\n",
    "\n",
    "        # define transformation\n",
    "        spectrogram = T.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\",\n",
    "            power=2.0,\n",
    "        )\n",
    "        # Perform transformation\n",
    "        waveform=torch.from_numpy(file)\n",
    "        spec = spectrogram(waveform)\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPS(Dataset):\n",
    "    def __init__(self):\n",
    "        #super().__init__(self)\n",
    "        self.daps= DAPSDatasetHelper()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data,label,_,_=self.daps.get_data(index)\n",
    "        data_spec=self.daps.getFeatures(data)\n",
    "        label_spec=self.daps.getFeatures(label)\n",
    "        return (data_spec,label_spec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.daps.keys)-1)*self.daps.num_files_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "USE_GPU = True\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model classes\n",
    "# create a class for linear layers \n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self,input_size,output_size,dropOut_p):\n",
    "        super().__init_(self)\n",
    "        self.dense=nn.Linear(input_size,output_size,bias=True)\n",
    "        self.activation=nn.Tanh()\n",
    "        self.dropOut=nn.Dropout(p=dropOut_p,inplace=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y=self.dense(x)\n",
    "        y=self.activation(y)\n",
    "        y=self.dropOut()\n",
    "\n",
    "        return y\n",
    "\n",
    "#class for convolutional layers\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,kernel_size,stride,padding,dropOut_p):\n",
    "        super().__init_(self)\n",
    "        self.conv=nn.Conv2d(in_ch,out_ch,kernel_size, stride=stride,padding=padding)\n",
    "        self.activation=nn.ReLU()\n",
    "        self.dropOut=nn.Dropout(p=dropOut_p,inplace=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y=self.conv(x)\n",
    "        y=self.activation(y)\n",
    "        y=self.dropOut()\n",
    "\n",
    "        return y\n",
    "\n",
    "#SNR loss where yhat is average power spectrum of de-nonlinearised/denoised signal/ clean signal power \n",
    "def Loss_SNR(yhat,y):\n",
    "    yhat=yhat.cpu().detach().numpy()\n",
    "    y=y.cpu().detach().numpy()\n",
    "    loss= np.mean(10*np.log(np.abs(yhat-y)/y))\n",
    "    loss=torch.from_numpy(loss)\n",
    "    loss=loss.to(device=device,dtype=dtype)\n",
    "    return loss\n",
    "\n",
    "#SNR loss where yhat is average power spectrum of de-nonlinearised/denoised signal/ clean signal power \n",
    "def Loss_MSE(yhat,y,lossfn):\n",
    "    loss=lossfn(yhat,y)\n",
    "    return loss\n",
    "\n",
    "#RNN model for Residual echo suppression\n",
    "class RES(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        super().__init__(self)\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim \n",
    "        self.rnn = nn.RNN(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "        self.fc1= DenseLayer(hidden_dim,output_dim,dropOut_p=dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN=20\n",
    "NUM_VAL=30\n",
    "NUM_TEST=10\n",
    "print_every = 100\n",
    "dataset_train = DAPS()\n",
    "loader_train = DataLoader(dataset_train, batch_size=1, num_workers=0,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "helper= DAPSDatasetHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer ,epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on DAPS.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: A Python function that performs the forward pass of the model.\n",
    "      It should have the signature scores = model_fn(x, params) where x is a\n",
    "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
    "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
    "      scores for the elements in x.\n",
    "    - params: List of PyTorch Tensors giving weights for the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
    "    \n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    lossfn=nn.MSELoss()\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            #iterate over each stft frame \n",
    "            x=x.to(device=device, dtype=dtype)\n",
    "            y=y.to(device=device, dtype=dtype)\n",
    "            x=torch.squeeze(x)\n",
    "            y=torch.squeeze(y)\n",
    "\n",
    "            for indx in range(x.shape[1]):\n",
    "                # Move the data to the proper device (GPU or CPU)\n",
    "                #size of each frame is (fft size /2) +1 since it's one sided spectrum\n",
    "                xframe = x[:,indx]\n",
    "                yframe = y[:,indx]\n",
    "\n",
    "                # Forward pass: compute scores and loss\n",
    "                yhat = model(xframe)\n",
    "                \n",
    "                loss = Loss_MSE(yhat, yframe,lossfn)\n",
    "\n",
    "                # Zero out all of the gradients for the variables which the optimizer\n",
    "                # will update.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # This is the backwards pass: compute the gradient of the loss with\n",
    "                # respect to each  parameter of the model.\n",
    "                loss.backward()\n",
    "\n",
    "                # Actually update the parameters of the model using the gradients\n",
    "                # computed by the backwards pass.\n",
    "                optimizer.step()\n",
    "                # Update parameters. We don't want to backpropagate through the\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                #check_accuracy_part2(loader_val, model_fn, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 40\n",
    "learning_rate = 1e-5\n",
    "frame_size=helper.fft_len//2 +1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(frame_size, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size,frame_size),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                     momentum=0.9, nesterov=True)\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, loss = 0.0428\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12617 is out of bounds for dimension 1 with size 12617",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/prasad/AEC/model/RNN_Res.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m train_model(model, optimizer)\n",
      "\u001b[1;32m/home/prasad/AEC/model/RNN_Res.ipynb Cell 8'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m indx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=26'>27</a>\u001b[0m     \u001b[39m# Move the data to the proper device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=27'>28</a>\u001b[0m     \u001b[39m#size of each frame is (fft size /2) +1 since it's one sided spectrum\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=28'>29</a>\u001b[0m     xframe \u001b[39m=\u001b[39m x[:,indx]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=29'>30</a>\u001b[0m     yframe \u001b[39m=\u001b[39m y[:,indx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=31'>32</a>\u001b[0m     \u001b[39m# Forward pass: compute scores and loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.110.119.158/home/prasad/AEC/model/RNN_Res.ipynb#ch0000007vscode-remote?line=32'>33</a>\u001b[0m     yhat \u001b[39m=\u001b[39m model(xframe)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12617 is out of bounds for dimension 1 with size 12617"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5c7ac77e593d0994949fe61f06040dedc773eb228097f0a804bc0d2d8d2f83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
