{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "from re import S\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DAPSDatasetHelper():\n",
    "\n",
    "    #Get the dataset dictionary \n",
    "    def get_file_descriptors(self,dirpath):\n",
    "        directory={}\n",
    "        dataset_path=self.dir\n",
    "        cwd= os.getcwd()\n",
    "        for i , (dirpath, dirname, filename) in enumerate(os.walk(dataset_path)):\n",
    "            if(dirpath!=dataset_path):\n",
    "                dirname=dirpath.split(\"/\")[-1]\n",
    "                files={}\n",
    "                file_list=[]\n",
    "                index=0\n",
    "                for file in filename:\n",
    "                    filepath = os.path.join( dirpath, file)\n",
    "                    if ( (filepath.endswith('.wav'))):\n",
    "                        if(file.startswith('.')):\n",
    "                            pass\n",
    "                        else:\n",
    "                            file_list.append(filepath)\n",
    "                file_list.sort()\n",
    "                if(len(file_list)>0):\n",
    "                    for filepath in file_list:\n",
    "                        files[index]=filepath\n",
    "                        index+=1\n",
    "                    directory[dirname]=files\n",
    "        return directory\n",
    "\n",
    "    #initialization \n",
    "    def __init__(self):\n",
    "        self.sample_rate=8000\n",
    "        self.dir= \"./dataset_daps/daps\"\n",
    "        self.dataset_dict=self.get_file_descriptors(self.dir)\n",
    "\n",
    "        #stft config\n",
    "        #frame size in ms\n",
    "        self.framesize=25\n",
    "        self.fft_len=self.sample_rate*self.framesize//1000\n",
    "        self.window_size=self.fft_len\n",
    "        self.hop_len=self.fft_len//2\n",
    "        self.num_files_per_category=len(self.dataset_dict[\"produced\"].keys())\n",
    "\n",
    "        indx=2\n",
    "        self.keys={}\n",
    "        for key  in self.dataset_dict.keys():\n",
    "            if(key==\"produced\"):\n",
    "                self.keys[1]=key\n",
    "            else:\n",
    "                self.keys[indx]=key\n",
    "                indx+=1\n",
    "\n",
    "    #get the indexed file and sample rate\n",
    "    def get_indxd_file(self,indx,isLabel=False):\n",
    "        if(isLabel):\n",
    "            category=self.keys[1]\n",
    "        else:\n",
    "            category=self.keys[np.random.randint(2,len(self.keys))]\n",
    "        data,sr= librosa.load(self.dataset_dict[category][indx])\n",
    "        Id= self.dataset_dict[category][indx].split(\"/\")[-1].split('.')[0]\n",
    "        return (data,sr, Id)\n",
    "\n",
    "    def resample_audio(self,file,sr):\n",
    "        out = librosa.resample(file, orig_sr=sr, target_sr=self.sample_rate)\n",
    "        return out\n",
    "\n",
    "    #get the train data and label at given index \n",
    "    def get_data(self,indx):\n",
    "        data,sr,Id_data = self.get_indxd_file(indx)\n",
    "        label,sr,Id_label = self.get_indxd_file(indx,True)\n",
    "        if(sr == self.sample_rate ):\n",
    "            pass\n",
    "        else:\n",
    "            data= self.resample_audio(data,sr)\n",
    "            label= self.resample_audio(label,sr)\n",
    "\n",
    "        return (data,label,Id_data,Id_label)\n",
    "\n",
    "\n",
    "    #get stft frames with 50% overlap\n",
    "    def getFeatures(self,file):\n",
    "\n",
    "        n_fft = self.fft_len\n",
    "        win_length = self.window_size\n",
    "        hop_length = self.hop_len\n",
    "\n",
    "        # define transformation\n",
    "        spectrogram = T.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\",\n",
    "            power=2.0,\n",
    "        )\n",
    "        # Perform transformation\n",
    "        waveform=torch.from_numpy(file)\n",
    "        spec = spectrogram(waveform)\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAPS(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "        self.daps= DAPSDatasetHelper()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data,label,_,_=self.daps.get_data(index)\n",
    "        data_spec=self.daps.getFeatures(data)\n",
    "        label_spec=self.daps.getFeatures(label)\n",
    "        return (data_spec,label_spec)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.daps.keys)-1)*self.daps.num_files_per_category"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5c7ac77e593d0994949fe61f06040dedc773eb228097f0a804bc0d2d8d2f83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
